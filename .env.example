# =============================================================================
# ARBITRAGEAI - COMPREHENSIVE ENVIRONMENT CONFIGURATION
# =============================================================================
# This file documents ALL environment variables used in the codebase.
# Copy this to .env and configure for your deployment.
# 
# Variable Types:
#   REQUIRED  - Must be set in production
#   OPTIONAL  - Has sensible defaults, optional to override
#   SECRET    - Should be kept secure, never commit actual values
#
# =============================================================================
# ENVIRONMENT & DEBUG (OPTIONAL)
# =============================================================================

# Deployment environment
# Valid: development, production
# Default: development
# When set to "production", disables local Phoenix observability dashboard
ENV=development
ENVIRONMENT=development

# Enable debug mode (verbose logging)
# Valid: true, false, 1, 0, yes, no
# Default: false
DEBUG=false

# Logging level
# Valid: DEBUG, INFO, WARNING, ERROR, CRITICAL
# Default: INFO
LOG_LEVEL=INFO

# =============================================================================
# LLM SERVICE CONFIGURATION (REQUIRED FOR CLOUD MODELS)
# =============================================================================

# OpenAI API Configuration
# Get your API key from https://platform.openai.com/api-keys
# Required if using cloud models
API_KEY=your-openai-api-key-here

# Alternative OpenAI API key name (use either API_KEY or OPENAI_API_KEY)
# OPENAI_API_KEY=your-openai-api-key-here

# Cloud LLM Base URL
# Default: https://api.openai.com/v1
# For Azure OpenAI, use your Azure endpoint URL
BASE_URL=https://api.openai.com/v1

# Default Cloud Model (for complex tasks requiring high accuracy)
# Valid: gpt-4o, gpt-4o-mini, gpt-4-turbo, gpt-3.5-turbo, etc.
# Default: gpt-4o-mini
CLOUD_MODEL=gpt-4o-mini

# =============================================================================
# LOCAL LLM CONFIGURATION (OPTIONAL - Ollama)
# =============================================================================

# Install Ollama from https://ollama.ai
# Run 'ollama serve' to start the local server
# Run 'ollama pull llama3.2' to download the model

# Ollama Local LLM Service Base URL
# Default: http://localhost:11434/v1
# Set to http://ollama:11434/v1 for Docker
OLLAMA_URL=http://localhost:11434/v1

# Ollama API endpoint (alternative naming)
# Default: http://localhost:11434/v1
LOCAL_BASE_URL=http://localhost:11434/v1

# Ollama API Key (usually not needed for local)
# Default: not-needed
LOCAL_API_KEY=not-needed

# Default Local Model Name (must be installed in Ollama)
# Default: llama3.2
LOCAL_MODEL=llama3.2

# =============================================================================
# MODEL SELECTION STRATEGY (OPTIONAL)
# =============================================================================

# Use local models by default for ALL tasks
# Valid: true, false
# Default: false (use cloud models for better quality)
# Set to "true" to maximize profit margins by using free local models
USE_LOCAL_BY_DEFAULT=false

# Task-specific model selection
# JSON map: task type → use local model (true) or cloud (false)
# Task types: basic_admin, complex, visualization, document, spreadsheet
# Example: {"basic_admin":true,"complex":false,"visualization":true}
# Default: All tasks use CLOUD_MODEL
TASK_USE_LOCAL_MAP={"basic_admin":true,"complex":false,"visualization":true,"document":true,"spreadsheet":true}

# Task-specific model override
# JSON map: task type → specific model name (optional)
# Leave empty to use default CLOUD_MODEL or LOCAL_MODEL
# Example: {"complex":"gpt-4o","basic_admin":"llama3.2"}
TASK_MODEL_MAP={}

# Revenue threshold for cloud vs local model selection
# In cents (3000 = $30)
# Below threshold: use local model (free)
# Above threshold: use cloud model (best quality)
# Default: 3000
MIN_CLOUD_REVENUE=3000

# =============================================================================
# DATABASE CONFIGURATION (OPTIONAL)
# =============================================================================

# Database URL for SQLAlchemy
# Format: sqlite:///./data/tasks.db (local, relative path)
# Format: postgresql://user:password@host/database (production)
# Format: mysql://user:password@host/database (MySQL)
# Default: SQLite at data/tasks.db
DATABASE_URL=sqlite:///./data/tasks.db

# =============================================================================
# REDIS CONFIGURATION - DISTRIBUTED LOCKING & CACHING (OPTIONAL)
# =============================================================================

# Option 1: Complete Redis URL (recommended)
# Format: redis://[password@]host:port/db
# Examples:
#   - Local: redis://localhost:6379/0
#   - With password: redis://:mypassword@redis.example.com:6379/0
#   - Docker: redis://redis:6379/0
# If set, this takes priority over separate REDIS_HOST/PORT/DB
REDIS_URL=redis://localhost:6379/0

# Option 2: Separate Redis configuration components
# Used if REDIS_URL is not set
# REDIS_HOST=localhost
# REDIS_PORT=6379
# REDIS_DB=0
# REDIS_PASSWORD=

# Enable Redis-backed distributed locks (Issue #19)
# Valid: true, false
# Default: Auto-detect (true if REDIS_URL/REDIS_HOST available, false in development)
# Explicit override: true → use Redis, false → use in-memory locks
# USE_REDIS_LOCKS=true

# =============================================================================
# SANDBOX & EXECUTION CONFIGURATION (OPTIONAL)
# =============================================================================

# Use Docker sandbox for code execution instead of E2B
# Valid: true, false
# Default: true
# Set to false to use E2B code interpreter (requires E2B_API_KEY)
USE_DOCKER_SANDBOX=true

# Docker image name for sandbox (must match Dockerfile.sandbox)
# Default: ai-sandbox-base
DOCKER_SANDBOX_IMAGE=ai-sandbox-base

# Docker sandbox execution timeout in seconds
# Default: 120 (2 minutes)
DOCKER_SANDBOX_TIMEOUT=120

# E2B Code Interpreter API Key (fallback if Docker sandbox disabled)
# Get from https://e2b.dev/docs/getting-started/api-key
# Required only if USE_DOCKER_SANDBOX=false
E2B_API_KEY=your-e2b-api-key-here

# =============================================================================
# PAYMENT & BILLING CONFIGURATION (REQUIRED IN PRODUCTION)
# =============================================================================

# Stripe API Configuration
# Get from https://dashboard.stripe.com/apikeys

# Stripe Secret Key (SECRET - never commit actual values)
# Required in production for payment processing
STRIPE_SECRET_KEY=sk_test_your_secret_key_here

# Stripe Webhook Secret (SECRET)
# Get from https://dashboard.stripe.com/webhooks
# Required for processing webhook events
STRIPE_WEBHOOK_SECRET=whsec_your_webhook_secret_here

# Stripe Publishable Key (safe to commit)
# Get from https://dashboard.stripe.com/apikeys
STRIPE_PUBLISHABLE_KEY=pk_test_your_publishable_key_here

# =============================================================================
# DELIVERY TOKEN CONFIGURATION (OPTIONAL)
# =============================================================================
# Issue #27: Delivery token security for task submissions

# Token time-to-live in hours
# Default: 1 (token valid for 1 hour)
DELIVERY_TOKEN_TTL_HOURS=1

# Maximum failed delivery attempts before account lockout
# Default: 5
DELIVERY_MAX_FAILED_ATTEMPTS=5

# Account lockout duration in seconds after max failed attempts
# Default: 3600 (1 hour)
DELIVERY_LOCKOUT_SECONDS=3600

# Maximum delivery attempts per IP address per hour
# Default: 20
DELIVERY_MAX_ATTEMPTS_PER_IP=20

# IP-based lockout duration in seconds
# Default: 3600 (1 hour)
DELIVERY_IP_LOCKOUT_SECONDS=3600

# =============================================================================
# CLIENT AUTHENTICATION (OPTIONAL)
# =============================================================================
# Issue #17: Client token-based authentication for dashboard

# HMAC secret for client token signing
# MUST be 32+ bytes in production (use: openssl rand -hex 32)
# Default: CHANGE_ME_IN_PRODUCTION_use_a_random_32_byte_key
# WARNING: Using default secret in production is a security risk
CLIENT_AUTH_SECRET=CHANGE_ME_IN_PRODUCTION_use_a_random_32_byte_key

# =============================================================================
# SANDBOX EXECUTION LIMITS (OPTIONAL) - Issue #26
# =============================================================================
# Configuration for code sandbox execution timeouts and limits

# Maximum sandbox timeout for complex tasks (seconds)
# Allows extra time for computationally intensive operations
# Default: 600 (10 minutes)
# Must be >= DOCKER_SANDBOX_TIMEOUT
SANDBOX_TIMEOUT_SECONDS=600

# =============================================================================
# DISTRIBUTED LOCKING CONFIGURATION (OPTIONAL) - Issue #19
# =============================================================================
# Configuration for bid lock manager TTL (time-to-live)

# Bid lock manager TTL in seconds
# Prevents duplicate bid placement during concurrent execution
# Default: 300 (5 minutes)
BID_LOCK_MANAGER_TTL=300

# =============================================================================
# FILE UPLOAD LIMITS (OPTIONAL) - Issue #26
# =============================================================================

# Maximum file upload size in bytes
# Default: 52428800 (50 MB)
# Range: 1KB to 1GB
MAX_FILE_SIZE_BYTES=52428800

# =============================================================================
# CIRCUIT BREAKER CONFIGURATION (OPTIONAL) - Issue #26
# =============================================================================

# URL circuit breaker cooldown duration in seconds
# Prevents hammering unresponsive URLs
# Default: 300 (5 minutes)
URL_CIRCUIT_BREAKER_COOLDOWN_SECONDS=300

# =============================================================================
# WEBHOOK SECURITY (OPTIONAL) - Issue #26
# =============================================================================

# Webhook timestamp validity window in seconds
# Prevents replay attacks by rejecting old webhooks
# Default: 300 (5 minutes)
WEBHOOK_TIMESTAMP_WINDOW=300

# =============================================================================
# LLM HEALTH CHECK CONFIGURATION (OPTIONAL) - Issue #26
# =============================================================================

# LLM health check response time history size
# Keep recent response times for latency averaging
# Default: 100 samples
LLM_HEALTH_CHECK_HISTORY_SIZE=100

# Initial backoff delay for health check retries in milliseconds
# Default: 100 (0.1 seconds)
LLM_HEALTH_CHECK_INITIAL_DELAY_MS=100

# Maximum backoff delay for health check retries in milliseconds
# Default: 10000 (10 seconds)
LLM_HEALTH_CHECK_MAX_DELAY_MS=10000

# =============================================================================
# MODEL DISTILLATION CONFIGURATION (OPTIONAL) - Issue #26
# =============================================================================

# Minimum examples needed for training distilled models
# Don't start training until we have enough examples
# Default: 500 examples
MIN_EXAMPLES_FOR_TRAINING=500

# =============================================================================
# COST OPTIMIZATION THRESHOLDS (OPTIONAL) - Issue #26
# =============================================================================

# Cloud GPT-4o output cost per 1M tokens in cents
# Used for cost optimization calculations
# Default: 1000 (cents) = $10 per 1M output tokens
CLOUD_GPT4O_OUTPUT_COST=1000

# Default task revenue estimate in cents
# Used when revenue not explicitly provided
# Default: 500 (cents) = $5
DEFAULT_TASK_REVENUE=500

# High-value task threshold in dollars
# Tasks >= this value are automatically escalated on failure for profit protection
# Default: 200 (dollars)
HIGH_VALUE_THRESHOLD=200

# =============================================================================
# MARKETPLACE SCANNING & AUTONOMOUS LOOP (OPTIONAL)
# =============================================================================

# Enable autonomous marketplace scanning at startup
# Valid: true, false
# Default: false
# Set to true to continuously scan marketplaces for profitable tasks
AUTONOMOUS_SCAN_ENABLED=false

# Marketplace configuration file
# JSON file containing discovered and configured marketplaces
# Default: data/marketplaces.json
MARKETPLACES_FILE=data/marketplaces.json

# [DEPRECATED] Single marketplace URL
# Kept for backward compatibility; if set, takes priority over MARKETPLACES_FILE
# Use MARKETPLACES_FILE for new deployments
# MARKETPLACE_URL=https://example.com/freelance-jobs

# LLM model to use for marketplace job evaluation
# Must be installed in Ollama (if using local models)
# Default: llama3.2
MARKET_SCAN_MODEL=llama3.2

# Page load timeout during marketplace scanning (seconds)
# Default: 30
MARKET_SCAN_PAGE_TIMEOUT=30

# Marketplace scan interval in seconds
# Default: 300 (5 minutes)
MARKET_SCAN_INTERVAL=300

# Bid amount range (in cents)
# MIN_BID_AMOUNT=10 means $0.10 minimum
# MAX_BID_AMOUNT=500 means $5.00 maximum
# Default: 10-500 cents ($0.10-$5.00)
MIN_BID_AMOUNT=10
MAX_BID_AMOUNT=500

# =============================================================================
# NOTIFICATIONS (OPTIONAL)
# =============================================================================
# Telegram Bot configuration for urgent alerts and human-in-the-loop requests

# Telegram Bot Token
# Get from @BotFather on Telegram
# Required to send Telegram notifications
TELEGRAM_BOT_TOKEN=your-telegram-bot-token-here

# Telegram Chat ID
# The chat/channel ID to receive notifications
# Can be found with @userinfobot on Telegram
# Required to send Telegram notifications
TELEGRAM_CHAT_ID=your-telegram-chat-id-here

# Telegram Bot API Base URL
# Default: https://api.telegram.org (official Telegram)
# Can be overridden for custom Telegram Bot API servers
TELEGRAM_API_URL=https://api.telegram.org

# =============================================================================
# SECURITY & FILE VALIDATION (OPTIONAL)
# =============================================================================

# Antivirus service to use for file scanning
# Valid: mock (default, no scanning), virustotal
# Default: mock
ANTIVIRUS_SERVICE=mock

# VirusTotal API Key (for file scanning)
# Get from https://www.virustotal.com/
# Required only if ANTIVIRUS_SERVICE=virustotal
VIRUSTOTAL_API_KEY=your-virustotal-api-key-here

# =============================================================================
# OBSERVABILITY & TRACING (OPTIONAL)
# =============================================================================

# OpenTelemetry Traceloop Collector URL
# For local development with Phoenix: http://localhost:6006/v1/traces
# For remote Traceloop instance: https://your-traceloop-endpoint/v1/traces
# Default: http://localhost:6006/v1/traces
TRACELOOP_URL=http://localhost:6006/v1/traces

# =============================================================================
# MODEL FINE-TUNING (OPTIONAL)
# =============================================================================

# Enable data capture for model fine-tuning (distillation)
# Valid: true, false
# Default: true
# Captures training examples to improve local model performance
ENABLE_DISTILLATION_CAPTURE=true

# =============================================================================
# CORS CONFIGURATION (OPTIONAL)
# =============================================================================

# CORS allowed origins (comma-separated)
# Default: http://localhost:5173 (local Vite frontend)
# Production examples:
#   - Single domain: https://example.com
#   - Multiple domains: https://example.com,https://app.example.com
#   - Wildcard: https://*.example.com (not recommended for production)
CORS_ORIGINS=http://localhost:5173

# Application base URL (for links in emails, webhooks, etc.)
# Default: http://localhost:5173
BASE_URL=http://localhost:5173

# =============================================================================
# QUICK START GUIDE
# =============================================================================
#
# For LOCAL DEVELOPMENT:
# 1. Copy this file: cp .env.example .env
# 2. Set minimum required variables:
#    - API_KEY (for cloud LLM)
#    - STRIPE_SECRET_KEY (for payments, can be test key)
#    - STRIPE_WEBHOOK_SECRET (for webhooks, can be test key)
# 3. Start services: just start
#
# For PRODUCTION:
# 1. Set all REQUIRED variables
# 2. Use secure SECRET values (NEVER use defaults)
# 3. Configure Redis for distributed locks
# 4. Set ENV=production
# 5. Use PostgreSQL instead of SQLite for DATABASE_URL
# 6. Configure proper Stripe keys from production account
# 7. Set up monitoring and alerting
#
# =============================================================================
